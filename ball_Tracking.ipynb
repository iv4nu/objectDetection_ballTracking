{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qavUOYuaD8bM"
      },
      "source": [
        "# Progetto Computer Vision - Prisco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "4l4ZQgRkOyNu",
        "outputId": "e8212b5a-f74e-4854-f4f2-4a5f4542b1ef"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "# **Metriche Obiettivo Finali**\n",
              "\n",
              "| **Metrica**    | **VIDEO 5** | **VIDEO 6** | **MEDIA**     |\n",
              "|----------------|-------------|-------------|---------------|\n",
              "| **MSE**        | 0.03840     | 0.00225     | 0.02035       |\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Crea una tabella markdown per mostrare le metriche\n",
        "table_md = \"\"\"\n",
        "# **Metriche Obiettivo Finali**\n",
        "\n",
        "| **Metrica**    | **VIDEO 5** | **VIDEO 6** | **MEDIA**     |\n",
        "|----------------|-------------|-------------|---------------|\n",
        "| **MSE**        | 0.03840     | 0.00225     | 0.02035       |\n",
        "\"\"\"\n",
        "\n",
        "# Mostra la tabella in Colab\n",
        "display(Markdown(table_md))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4k67l2_D5j2"
      },
      "source": [
        "\n",
        "\n",
        "## Modello scelto:\n",
        "   ### YOLO11\n",
        "![](https://cdn.prod.website-files.com/6479eab6eb2ed5e597810e9e/66f680814693dd5c3b60dfcb_YOLO11_Thumbnail.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqbAzREmEb9b"
      },
      "source": [
        "## Operazioni preliminari e installazione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nTzbgBawEtWa",
        "outputId": "ca2756b7-92d0-43a4-e9bf-69530ab41b35"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mQuaXZVEg5k"
      },
      "source": [
        "Si importano le classi di utilità per calcolare le metriche"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lr1fJHT0CQzD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "52nm7zMaCLSf"
      },
      "outputs": [],
      "source": [
        "class TrackingEvaluator:\n",
        "    def __init__(self, gt_ann_file, pred_file):\n",
        "        self.gt_ann_file = gt_ann_file\n",
        "        self.pred_file = pred_file\n",
        "        self.gt_data_points = {}\n",
        "        self.pred_points = {}\n",
        "        self.frames_idx = None\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_points_data(xml_content):\n",
        "        root = ET.fromstring(xml_content)\n",
        "        points_data = {}\n",
        "\n",
        "        for track in root.findall(\".//track\"):\n",
        "            for point in track.findall(\"points\"):\n",
        "                data = {\n",
        "                    'frame': int(point.get(\"frame\")),\n",
        "                    'outside': int(point.get(\"outside\")),\n",
        "                    'occluded': int(point.get(\"occluded\")),\n",
        "                    'keyframe': int(point.get(\"keyframe\")),\n",
        "                    'points': tuple(map(float, point.get(\"points\").split(\",\"))),\n",
        "                    'z_order': int(point.get(\"z_order\")),\n",
        "                }\n",
        "                if data['frame'] in points_data:\n",
        "                    print(f'Alert: multiple frame entries for ID {data[\"frame\"]}')\n",
        "                points_data[data['frame']] = data\n",
        "\n",
        "        return points_data\n",
        "\n",
        "    @staticmethod\n",
        "    def _convert_key(k):\n",
        "        return int(Path(k).stem)\n",
        "\n",
        "    def load_data(self):\n",
        "        # Load ground truth data\n",
        "        gt_content = Path(self.gt_ann_file).read_text()\n",
        "        self.gt_data_points = self.extract_points_data(gt_content)\n",
        "\n",
        "        # Load prediction data\n",
        "        pred_content = Path(self.pred_file).read_text().replace('-Infinity', '-1').replace('Infinity', '-1')\n",
        "        raw_pred_points = json.loads(pred_content)\n",
        "        self.pred_points = {\n",
        "            self._convert_key(k): v for k, v in raw_pred_points.items() if v['x'] >= 0\n",
        "        }\n",
        "\n",
        "    def compute_frame_indices(self):\n",
        "        ordered_list_pred_frame = sorted(self.pred_points.keys())\n",
        "        ordered_list_gt_frame = sorted(self.gt_data_points.keys())\n",
        "\n",
        "        print(f'GT   frames: {ordered_list_gt_frame[0]} - {ordered_list_gt_frame[-1]}')\n",
        "        print(f'PRED frames: {ordered_list_pred_frame[0]} - {ordered_list_pred_frame[-1]}')\n",
        "\n",
        "        self.frames_idx = (\n",
        "            min(ordered_list_gt_frame[0], ordered_list_pred_frame[0]),\n",
        "            max(ordered_list_gt_frame[-1], ordered_list_pred_frame[-1]),\n",
        "        )\n",
        "        print(f'Frame Index Range: {self.frames_idx}')\n",
        "\n",
        "    @staticmethod\n",
        "    def is_match(x1, y1, x2, y2, threshold=4):\n",
        "        p1 = np.array((x1, y1))\n",
        "        p2 = np.array((x2, y2))\n",
        "        euclid_dist = np.sqrt(np.dot((p1 - p2).T, (p1 - p2)))\n",
        "        return euclid_dist < threshold\n",
        "\n",
        "    def evaluate_metrics(self):\n",
        "        cnt_match = 0\n",
        "        cnt_no_match = 0\n",
        "        cnt_no_pred = 0\n",
        "        cnt_no_frame = 0\n",
        "\n",
        "        for i in range(self.frames_idx[0], self.frames_idx[1] + 1):\n",
        "            if i not in self.gt_data_points:\n",
        "                cnt_no_frame += 1\n",
        "                continue\n",
        "            if i not in self.pred_points:\n",
        "                cnt_no_pred += 1\n",
        "                continue\n",
        "\n",
        "            p1 = self.gt_data_points[i]\n",
        "            p2 = self.pred_points[i]\n",
        "\n",
        "            if self.is_match(*p1['points'], p2['x'], p2['y']):\n",
        "                cnt_match += 1\n",
        "            else:\n",
        "                cnt_no_match += 1\n",
        "\n",
        "        total_frames = len(self.gt_data_points)\n",
        "        print(f'Total frames: {total_frames}')\n",
        "        print(f'Total predictions: {len(self.pred_points)}')\n",
        "        print(f'Matches: {cnt_match} ({cnt_match / total_frames:.3f})')\n",
        "        print(f'No matches: {cnt_no_match} ({cnt_no_match / total_frames:.3f})')\n",
        "        print(f'No predictions: {cnt_no_pred} ({cnt_no_pred / total_frames:.3f})')\n",
        "        print(f'No frame data: {cnt_no_frame} ({cnt_no_frame / (self.frames_idx[1] - self.frames_idx[0] + 1):.3f})')\n",
        "\n",
        "    def compute_tracking_sequence(self):\n",
        "        norm_width = 1920\n",
        "        norm_height = 1080\n",
        "\n",
        "        gt_seq = []\n",
        "        pred_seq = []\n",
        "\n",
        "        for i in range(min(self.gt_data_points.keys()), max(self.gt_data_points.keys()) + 1):\n",
        "            if i in self.gt_data_points:\n",
        "                if i not in self.pred_points:\n",
        "                    pred_seq.append((0, 0))\n",
        "                else:\n",
        "                    p2 = self.pred_points[i]\n",
        "                    pred_seq.append((p2['x'] / norm_width, p2['y'] / norm_height))\n",
        "\n",
        "                x, y = self.gt_data_points[i]['points']\n",
        "                gt_seq.append((x / norm_width, y / norm_height))\n",
        "\n",
        "        return gt_seq, pred_seq\n",
        "\n",
        "    def compute_mse(self):\n",
        "        gt_seq, pred_seq = self.compute_tracking_sequence()\n",
        "        mse = mean_squared_error(gt_seq, pred_seq)\n",
        "        print(f'Mean Squared Error: {mse}')\n",
        "        return mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN8WImOm7cQf"
      },
      "source": [
        "### Preprocessing ed estrazione dei frame dai video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmfg7ED5lIuR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import cv2\n",
        "\n",
        "def convert_xml_and_extract_frames(video_path, xml_file, frames_dir, labels_dir, img_width, img_height, video_name):\n",
        "    # Parse XML e identifica i frame annotati\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    os.makedirs(frames_dir, exist_ok=True)\n",
        "    os.makedirs(labels_dir, exist_ok=True)\n",
        "\n",
        "    annotated_frames = {}  # Mappa frame -> annotazioni\n",
        "    for points in root.findall(\".//points\"):\n",
        "        frame = int(points.get(\"frame\"))\n",
        "        outside = int(points.get(\"outside\"))\n",
        "        used_in_game = points.find(\".//attribute[@name='used_in_game']\").text if points.find(\".//attribute[@name='used_in_game']\") is not None else \"1\"\n",
        "\n",
        "        # Ottieni le informazioni di annotazione per ogni frame\n",
        "        x, y = map(float, points.get(\"points\").split(\",\"))\n",
        "\n",
        "        # Se \"used_in_game\" è uguale a 0, il frame deve essere ignorato, quindi non ha annotazioni\n",
        "        if used_in_game == \"0\":\n",
        "            annotated_frames[frame] = \"\"  # File vuoto\n",
        "        else:\n",
        "            # Normalizzazione delle coordinate\n",
        "            x_center = x / img_width\n",
        "            y_center = y / img_height\n",
        "            width = 0.05  # Approssimazione della dimensione\n",
        "            height = 0.05\n",
        "            # Se il frame è visibile (outside=0), crea le annotazioni\n",
        "            if outside == 0:\n",
        "                annotated_frames[frame] = f\"0 {x_center} {y_center} {width} {height}\\n\"\n",
        "            else:\n",
        "                # Se fuori dal campo (outside=1), puoi scrivere un file txt vuoto o con una convenzione YOLO\n",
        "                annotated_frames[frame] = \"\"  # File vuoto o con un formato che YOLO comprende come \"assenza di oggetti\"\n",
        "\n",
        "    # Estrai i frame dal video e genera i file .txt\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Crea il nome del frame\n",
        "        frame_name = f\"{video_name}_frame{frame_count:06d}.jpg\"  # Salva come .jpg\n",
        "        frame_file_path = os.path.join(frames_dir, frame_name)\n",
        "\n",
        "        # Salva il frame come immagine JPEG con qualità 90\n",
        "        cv2.imwrite(frame_file_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 90])\n",
        "\n",
        "        # Crea il file .txt (anche per i frame senza annotazioni)\n",
        "        txt_file_path = os.path.join(labels_dir, f\"{video_name}_frame{frame_count:06d}.txt\")\n",
        "        with open(txt_file_path, \"w\") as f:\n",
        "            # Se ci sono annotazioni, scrivile nel file, altrimenti crea un file vuoto\n",
        "            annotation = annotated_frames.get(frame_count, \"\")\n",
        "            if annotation == \"\":  # Se non ci sono annotazioni o se used_in_game=0\n",
        "                # In YOLO, un file vuoto significa \"assenza di oggetti\"\n",
        "                f.write(\"\")  # Scrive un file vuoto o puoi scrivere una convenzione YOLO (ad esempio '0 0 0 0 0')\n",
        "            else:\n",
        "                f.write(annotation)  # Scrive la label (con annotazioni)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qLwe_yHmeYT",
        "outputId": "14a2034d-adf4-4c58-b602-f633645bc74b"
      },
      "outputs": [],
      "source": [
        "# Creazione di una cartella unica per tutti i frame e le etichette\n",
        "frames_output_dir = \"/content/drive/MyDrive/dataset/train/images\"\n",
        "labels_output_dir = \"/content/drive/MyDrive/dataset/train/labels\"\n",
        "\n",
        "# Esegui per ciascun video e XML nella cartella dataset su Google Drive\n",
        "videos = [\n",
        "    (\"ID-1\", \"/content/drive/MyDrive/dataset/dataset_soccer/train/ID-1.avi\", \"/content/drive/MyDrive/dataset/dataset_soccer/train/ID-1.xml\"),\n",
        "    (\"ID-2\", \"/content/drive/MyDrive/dataset/dataset_soccer/train/ID-2.avi\", \"/content/drive/MyDrive/dataset/dataset_soccer/train/ID-2.xml\"),\n",
        "    (\"ID-3\", \"/content/drive/MyDrive/dataset/dataset_soccer/train/ID-3.avi\", \"/content/drive/MyDrive/dataset/dataset_soccer/train/ID-3.xml\"),\n",
        "    (\"ID-4\", \"/content/drive/MyDrive/dataset/dataset_soccer/train/ID-4.avi\", \"/content/drive/MyDrive/dataset/dataset_soccer/train/ID-4.xml\")\n",
        "]\n",
        "\n",
        "for video_name, video_path, xml_file in videos:\n",
        "    convert_xml_and_extract_frames(\n",
        "        video_path=video_path,\n",
        "        xml_file=xml_file,\n",
        "        frames_dir=frames_output_dir,\n",
        "        labels_dir=labels_output_dir,\n",
        "        img_width=1920,\n",
        "        img_height=1088,\n",
        "        video_name=video_name\n",
        "    )\n",
        "\n",
        "print(\"Tutti i frame e le etichette sono stati salvati nelle rispettive cartelle su Google Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tU27rezyvMe",
        "outputId": "2daecac0-7f78-4d41-8267-028249d3bf66"
      },
      "outputs": [],
      "source": [
        "# Creazione di una cartella unica per tutti i frame e le etichette\n",
        "frames_output_dir = \"/content/drive/MyDrive/dataset/test/images\"\n",
        "labels_output_dir = \"/content/drive/MyDrive/dataset/test/labels\"\n",
        "\n",
        "# Esegui per ciascun video e XML nella cartella dataset su Google Drive\n",
        "videos = [\n",
        "    (\"ID-5\", \"/content/drive/MyDrive/dataset/dataset_soccer/test/ID-5.avi\", \"/content/drive/MyDrive/dataset/dataset_soccer/test/ID-5.xml\"),\n",
        "    (\"ID-6\", \"/content/drive/MyDrive/dataset/dataset_soccer/test/ID-6.avi\", \"/content/drive/MyDrive/dataset/dataset_soccer/test/ID-6.xml\"),\n",
        "\n",
        "]\n",
        "\n",
        "for video_name, video_path, xml_file in videos:\n",
        "    convert_xml_and_extract_frames(\n",
        "        video_path=video_path,\n",
        "        xml_file=xml_file,\n",
        "        frames_dir=frames_output_dir,\n",
        "        labels_dir=labels_output_dir,\n",
        "        img_width=1920,\n",
        "        img_height=1088,\n",
        "        video_name=video_name\n",
        "    )\n",
        "\n",
        "print(\"Tutti i frame e le etichette sono stati salvati nelle rispettive cartelle su Google Drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONvzUYKJFBc-"
      },
      "source": [
        "Per le operazioni di preparazione del dataset, è stato utilizzato il tool online **Roboflow**, che ha svolto un ruolo fondamentale nel migliorare la qualità e la quantità dei dati. In particolare, grazie alle sue funzionalità di **data augmentation**, è stato possibile ottenere una **triplicazione degli esempi positivi**, generando varianti delle immagini originali con trasformazioni come rotazioni, ridimensionamenti e modifiche di luminosità. Questo ha consentito di migliorare significativamente la capacità del modello di generalizzare a situazioni diverse.\n",
        "\n",
        "Le principali operazioni sono state:\n",
        "1. Flip: Horizontal & Vertical\n",
        "2. Random brigthness [-15%,+15%]\n",
        "3. Blur: fino a 1.4px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qat93v7aGHJ4"
      },
      "source": [
        "![](https://cdn.prod.website-files.com/5f6bc60e665f54545a1e52a5/611410d27864224708a6502f_logo.webp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGk7hDwY8AiR"
      },
      "source": [
        "# ADDESTRAMENTO DEL MODELLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmQmDf7bWzM9"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPHQ8zMb8ef_"
      },
      "source": [
        "Per il nostro progetto, abbiamo scelto YOLO (You Only Look Once) come modello di riferimento per la rilevazione degli oggetti. La decisione è stata motivata da diverse considerazioni che riguardano le esigenze specifiche del nostro scenario e le caratteristiche tecniche di YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ek2QDdzW7OL",
        "outputId": "b500ee68-0877-4a05-99a4-9d3c0efb4d31"
      },
      "outputs": [],
      "source": [
        "model=YOLO('yolo11n.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdP6dBXn8-Ml"
      },
      "source": [
        "Per il nostro progetto, abbiamo addestrato un primo modello YOLO utilizzando il nostro dataset personalizzato, arricchito con tecniche di data augmentation per migliorare la robustezza e la generalizzazione del modello. Di seguito sono riportati i dettagli principali della fase di addestramento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umMBzGZg9sQz"
      },
      "outputs": [],
      "source": [
        "model=YOLO('yolo11n.pt')\n",
        "model.train(\n",
        "    data='/content/drive/MyDrive/model/yolo_output/training_yolo.yaml',  # File YAML del dataset\n",
        "    epochs=30,  # Numero di epoche\n",
        "    batch=16,    # Dimensione del batch\n",
        "    imgsz=1024,  # Dimensione dell'immagine\n",
        "    patience=4, #Early stop dopo 4 epoche\n",
        "    conf=0.2, #Abbassiamo la confidenza di predizione a 0.2\n",
        "    warmup_epochs=3,\n",
        "    lr0=0.0005, # Learning rate iniziale (più basso per una convergenza più stabile)\n",
        "    lrf=0.01,   # Learning rate finale\n",
        "    save=True,     # Salva i pesi\n",
        "    save_period=5, # Salva ogni 5 epoche\n",
        "    project='/content/drive/MyDrive/model/yolo_output',  # Salvataggio modello\n",
        "    device='cuda', # Usa la GPU\n",
        "    workers=4,         # Numero di workers per il caricamento\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSwnyoxBHBVo"
      },
      "source": [
        "#Calcolo delle predizioni in un file json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRirLUXk-gb6"
      },
      "source": [
        "Ottenuto il nostro modello, procediamo con le predizioni"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf8Or_CvQ-43"
      },
      "source": [
        "## Costruzione Json unico con predizioni di entrambi i video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Dj6JadUTdQwC",
        "outputId": "6c6ced44-3e2a-4e75-d5be-e7f7037cd5a0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from ultralytics import YOLO\n",
        "import numpy as np  # Per la gestione degli array\n",
        "\n",
        "model_path = \"/content/drive/MyDrive/model/yolo_output/train/weights/best.pt\"  # O il percorso del modello che vuoi caricare\n",
        "\n",
        "# Carica il modello\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Percorso alla cartella con i frame di test\n",
        "test_frames_dir = '/content/drive/MyDrive/dataset/test/images'\n",
        "\n",
        "# Crea una lista dei file immagine (frame di test)\n",
        "test_images = [os.path.join(test_frames_dir, f) for f in os.listdir(test_frames_dir) if f.endswith(('.jpg', '.png'))]\n",
        "\n",
        "# Dizionario per memorizzare le predizioni in formato JSON\n",
        "predictions = {}\n",
        "\n",
        "# Esegui le predizioni per ogni immagine di test\n",
        "for image_path in test_images:\n",
        "    # Ottieni il nome del file (ad esempio, \"ID-6_frame002000.jpg\")\n",
        "    file_name = os.path.basename(image_path)\n",
        "\n",
        "    # Esegui la predizione sul frame\n",
        "    results = model.predict(image_path,imgsz=1024)\n",
        "\n",
        "    # Controlla se ci sono predizioni (bounding boxes)\n",
        "    if len(results[0].boxes) > 0:  # Se ci sono delle predizioni (risultati)\n",
        "        boxes = results[0].boxes.xywh.tolist()  # Bounding boxes\n",
        "        classes = results[0].boxes.cls.tolist()  # Classi delle predizioni\n",
        "        names = results[0].names  # Nomi delle classi\n",
        "        confidences = results[0].boxes.conf.tolist()  # Confidenze delle predizioni\n",
        "\n",
        "        # Iterate attraverso i risultati\n",
        "        for box, cls, conf in zip(boxes, classes, confidences):\n",
        "            x_center, y_center, width, height = box  # Coordinate del bounding box\n",
        "            confidence = conf\n",
        "            detected_class = cls\n",
        "            name = names[int(cls)]\n",
        "\n",
        "            # Calcola la posizione del centro del bounding box\n",
        "            x_center_pixel = x_center  \n",
        "            y_center_pixel = y_center  \n",
        "\n",
        "            # Aggiungi il file e la predizione al dizionario\n",
        "            predictions[file_name] = {\"x\": float(x_center_pixel), \"y\": float(y_center_pixel)}  # Converte in float per serializzazione\n",
        "\n",
        "    else: predictions[file_name] = {\"x\": -1, \"y\": -1}\n",
        "\n",
        "# Salva le predizioni in un file JSON\n",
        "predictions_file = '/content/drive/MyDrive/model/yolo_output/predictions_final.json'\n",
        "with open(predictions_file, 'w') as f:\n",
        "    json.dump(predictions, f, indent=4)\n",
        "\n",
        "print(f\"Le predizioni sono state salvate in: {predictions_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ciyVgic2M3n",
        "outputId": "b011b17d-b341-43b5-870d-dcfed2273d99"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Percorso del file JSON originale\n",
        "pred_file = '/content/drive/MyDrive/model/yolo_output/predictions_final.json'\n",
        "\n",
        "# Carica il file JSON delle predizioni\n",
        "with open(pred_file, 'r') as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "# Crea due dizionari per separare le predizioni per il video 5 e video 6\n",
        "predictions_video_5 = {}\n",
        "predictions_video_6 = {}\n",
        "\n",
        "# Loop attraverso tutte le predizioni\n",
        "for frame_name, coords in predictions.items():\n",
        "    if \"ID-5\" in frame_name:  # Verifica se il frame appartiene al video 5\n",
        "        predictions_video_5[frame_name] = coords\n",
        "    elif \"ID-6\" in frame_name:  # Verifica se il frame appartiene al video 6\n",
        "        predictions_video_6[frame_name] = coords\n",
        "\n",
        "# Salva le predizioni per il video 5 in un nuovo file JSON\n",
        "video_5_pred_file = '/content/drive/MyDrive/model/yolo_output/predictions_video_5_final.json'\n",
        "with open(video_5_pred_file, 'w') as f:\n",
        "    json.dump(predictions_video_5, f, indent=4)\n",
        "\n",
        "# Salva le predizioni per il video 6 in un nuovo file JSON\n",
        "video_6_pred_file = '/content/drive/MyDrive/model/yolo_output/predictions_video_6_final.json'\n",
        "with open(video_6_pred_file, 'w') as f:\n",
        "    json.dump(predictions_video_6, f, indent=4)\n",
        "\n",
        "print(f\"Predizioni video 5 salvate in: {video_5_pred_file}\")\n",
        "print(f\"Predizioni video 6 salvate in: {video_6_pred_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY8VwsVY18w4"
      },
      "source": [
        "### Creazione Json per video 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lal2yKV-zOvv",
        "outputId": "2287e9f7-0b13-4f71-ad15-561abbcd6093"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Percorso del file JSON per le predizioni del video 5\n",
        "pred_file = '/content/drive/MyDrive/model/yolo_output/predictions_video_5_final.json'\n",
        "\n",
        "# Carica il file JSON delle predizioni\n",
        "with open(pred_file, 'r') as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "# Crea un nuovo dizionario con i nomi modificati\n",
        "modified_predictions = {}\n",
        "\n",
        "# Modifica il nome del frame rimuovendo la parte 'ID-5_frame' e lascia solo il numero del frame\n",
        "for frame_name, coords in predictions.items():\n",
        "    # Estrai la parte numerica del nome del file (rimuovi \"ID-5_frame\" se presente)\n",
        "    new_frame_name = frame_name.replace(\"ID-5_frame\", \"\")\n",
        "\n",
        "    # Aggiungi al dizionario modificato con il nuovo nome del frame\n",
        "    modified_predictions[new_frame_name] = coords\n",
        "\n",
        "# Salva le predizioni con i nuovi nomi in un nuovo file JSON\n",
        "modified_pred_file = '/content/drive/MyDrive/model/yolo_output/modified_predictions_video_5.json'\n",
        "with open(modified_pred_file, 'w') as f:\n",
        "    json.dump(modified_predictions, f, indent=4)\n",
        "\n",
        "print(f\"Le predizioni modificate sono state salvate in: {modified_pred_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHlmxT962CGm"
      },
      "source": [
        "### Creazione Json per video 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGV4Wz020A0G",
        "outputId": "fb2107ed-8e3e-40cc-90ea-9c7012fd6ffd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Percorso del file JSON per le predizioni del video 5\n",
        "pred_file = '/content/drive/MyDrive/model/yolo_output/predictions_video_6_final.json'\n",
        "\n",
        "# Carica il file JSON delle predizioni\n",
        "with open(pred_file, 'r') as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "# Crea un nuovo dizionario con i nomi modificati\n",
        "modified_predictions = {}\n",
        "\n",
        "# Modifica il nome del frame rimuovendo la parte 'ID-5_frame' e lascia solo il numero del frame\n",
        "for frame_name, coords in predictions.items():\n",
        "    # Estrai la parte numerica del nome del file (rimuovi \"ID-5_frame\" se presente)\n",
        "    new_frame_name = frame_name.replace(\"ID-6_frame\", \"\")\n",
        "\n",
        "    # Aggiungi al dizionario modificato con il nuovo nome del frame\n",
        "    modified_predictions[new_frame_name] = coords\n",
        "\n",
        "# Salva le predizioni con i nuovi nomi in un nuovo file JSON\n",
        "modified_pred_file = '/content/drive/MyDrive/model/yolo_output/modified_predictions_video_6.json'\n",
        "with open(modified_pred_file, 'w') as f:\n",
        "    json.dump(modified_predictions, f, indent=4)\n",
        "\n",
        "print(f\"Le predizioni modificate sono state salvate in: {modified_pred_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PbVQn28-wz0"
      },
      "source": [
        "Andiamo a fare una prima valutazione delle metriche obiettivo dopo assicurati degli altri parametri come precision,recall,loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3IES2DA-94J",
        "outputId": "d0096c45-967f-450d-e12b-c13911511f78"
      },
      "outputs": [],
      "source": [
        "# Percorsi ai tuoi file\n",
        "gt_ann_file = '/content/drive/MyDrive/dataset/dataset_soccer/test/ID-5.xml'  # Ground truth file\n",
        "pred_file = '/content/drive/MyDrive/model/yolo_output/modified_predictions_video_5.json'  # Predizioni in formato JSON\n",
        "\n",
        "# Creazione dell'oggetto evaluator\n",
        "evaluator = TrackingEvaluator(gt_ann_file, pred_file)\n",
        "\n",
        "# Caricamento dei dati\n",
        "evaluator.load_data()\n",
        "\n",
        "# Calcolare gli indici dei frame\n",
        "evaluator.compute_frame_indices()\n",
        "\n",
        "# Valutazione delle metriche\n",
        "evaluator.evaluate_metrics()\n",
        "\n",
        "# Calcolare MSE\n",
        "mse1 = evaluator.compute_mse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0qy0H0u_Lx8",
        "outputId": "fdb265bb-72b4-463e-b551-68c75e248e00"
      },
      "outputs": [],
      "source": [
        "# Percorsi ai tuoi file\n",
        "gt_ann_file = '/content/drive/MyDrive/dataset/dataset_soccer/test/ID-6.xml'  # Ground truth file\n",
        "pred_file = '/content/drive/MyDrive/model/yolo_output/modified_predictions_video_6.json'  # Predizioni in formato JSON\n",
        "\n",
        "# Creazione dell'oggetto evaluator\n",
        "evaluator = TrackingEvaluator(gt_ann_file, pred_file)\n",
        "\n",
        "# Caricamento dei dati\n",
        "evaluator.load_data()\n",
        "\n",
        "# Calcolare gli indici dei frame\n",
        "evaluator.compute_frame_indices()\n",
        "\n",
        "# Valutazione delle metriche\n",
        "evaluator.evaluate_metrics()\n",
        "\n",
        "# Calcolare MSE\n",
        "mse2 = evaluator.compute_mse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRtmRb1w_TVr",
        "outputId": "77b8ce7f-b6f4-42d4-c581-39219d427b1e"
      },
      "outputs": [],
      "source": [
        "media=(mse1+mse2)/2\n",
        "print(\"MSE medio calcolato =\",media)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1eKm4EC_jeh"
      },
      "source": [
        "Come possiamo notare abbiamo ottenuto dei primi risultati che mostrano un modello buono ma che ancora presenta punti di debolezza in situazione di occlusione e bordi, tuttavia attraverso l'attività di post processing si possono migliorare ulteriormente le predizioni.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHNF6Ca7JVFY"
      },
      "source": [
        "Ordiniamo le predizioni e procediamo con le operazioni di post processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wip4b4gk7dH",
        "outputId": "661e767a-64a3-4514-fff1-5b5a3fb213ec"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# Percorso del file JSON di input e output\n",
        "input_file = '/content/drive/MyDrive/model/yolo_output/modified_predictions_video_5.json'\n",
        "output_file = '/content/drive/MyDrive/model/yolo_output/video5_ordinato.json'\n",
        "\n",
        "# Ordina i frame per nome (numerico) per garantire l'ordine corretto\n",
        "def extract_frame_number(frame_name):\n",
        "    \"\"\"Estrai il numero del frame dalla stringa del nome del file.\"\"\"\n",
        "    return int(frame_name.split('_')[-1].replace('.jpg', '').replace('.png', '').replace('frame', ''))\n",
        "\n",
        "\n",
        "\n",
        "# Carica il file JSON di input\n",
        "with open(input_file, 'r') as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "sorted_predictions = dict(sorted(predictions.items(), key=lambda item: extract_frame_number(item[0])))\n",
        "\n",
        "# Salva il file JSON con i frame estesi\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(sorted_predictions, f, indent=4)\n",
        "\n",
        "print(f\"Predizioni estese salvate in: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HybuI8Qf_yH4"
      },
      "source": [
        "# Post Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmZq443g_8ZC"
      },
      "source": [
        "## 1 Fase: Eliminiamo i falsi positivi\n",
        "In una prima fase andiamo ad eliminare le predizioni isolate , ovvero le predizioni che erroneamente il modello ha predetto.\n",
        "utilizziamo la logica di fare detection di alcuni punti di cumulo isolati e statici.\n",
        "\n",
        "Il pallone,infatti, è solitamente visibile in aree di gioco dinamiche, dove ci sono interazioni tra i giocatori e il movimento del gioco. Predizioni isolate in punti del campo poco utilizzati (es. centro fisso del frame o angoli statici) non sono coerenti con le dinamiche del gioco.\n",
        "Inoltre, il pallone non è presente continuamente nel campo visivo, ad esempio, quando viene calciato fuori o è coperto da altri oggetti.\n",
        "\n",
        "Predizioni isolate possono rappresentare:\n",
        "* Rilevamenti errati dovuti a elementi visivamente simili al pallone (es. linee bianche, luci riflettenti).\n",
        "* Errori sistematici del modello in aree poco rappresentative del dataset di training.\n",
        "\n",
        "Queste predizioni tendono a creare rumore nei risultati, riducendo la precisione complessiva del modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WICwo8Z86Nr9",
        "outputId": "acab7434-5abf-406c-cfe1-e37d4c2b71d9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "\n",
        "# Percorso del file JSON di input e output\n",
        "input_file = '/content/drive/MyDrive/model/yolo_output/video5_ordinato.json'\n",
        "output_file = '/content/drive/MyDrive/model/yolo_output/video5_SenzaOutlier.json'\n",
        "\n",
        "# Carica il file JSON di input\n",
        "with open(input_file, 'r') as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "# Converte le predizioni in una lista per iterazione\n",
        "frames = list(predictions.keys())\n",
        "values = list(predictions.values())\n",
        "\n",
        "# Parametri\n",
        "window_size = 40  # Dimensione della finestra\n",
        "static_threshold = 5  # Soglia massima di differenza per considerare i frame \"statici\"\n",
        "min_neighbors = 5  # Numero minimo di frame -1, -1 richiesti prima e dopo il blocco\n",
        "\n",
        "# Funzione per calcolare se un blocco è statico\n",
        "def is_static_block(values, start, end, threshold):\n",
        "    \"\"\"Verifica se il blocco è statico.\"\"\"\n",
        "    for i in range(start, end - 1):\n",
        "        if values[i][\"x\"] != -1 and values[i][\"y\"] != -1 and values[i + 1][\"x\"] != -1 and values[i + 1][\"y\"] != -1:\n",
        "            dx = abs(values[i][\"x\"] - values[i + 1][\"x\"])\n",
        "            dy = abs(values[i][\"y\"] - values[i + 1][\"y\"])\n",
        "            if dx > threshold or dy > threshold:\n",
        "                return False\n",
        "    return True\n",
        "\n",
        "# Funzione per controllare se ci sono abbastanza frame -1, -1 prima e dopo il blocco\n",
        "def has_null_neighbors(values, start, end, min_neighbors):\n",
        "    \"\"\"Verifica se ci sono almeno `min_neighbors` frame -1, -1 prima e dopo il blocco.\"\"\"\n",
        "    before = all(values[max(0, start - i)][\"x\"] == -1 and values[max(0, start - i)][\"y\"] == -1 for i in range(1, min_neighbors + 1))\n",
        "    after = all(values[min(len(values) - 1, end + i)][\"x\"] == -1 and values[min(len(values) - 1, end + i)][\"y\"] == -1 for i in range(1, min_neighbors + 1))\n",
        "    return before and after\n",
        "\n",
        "# Depura il file JSON\n",
        "cleaned_predictions = predictions.copy()\n",
        "\n",
        "for i in range(len(values) - window_size + 1):\n",
        "    # Definisci la finestra\n",
        "    start = i\n",
        "    end = i + window_size\n",
        "\n",
        "    # Trova il primo e l'ultimo frame validi nella finestra\n",
        "    valid_frames = [j for j in range(start, end) if values[j][\"x\"] != -1 and values[j][\"y\"] != -1]\n",
        "\n",
        "    if len(valid_frames) > 2:  # Deve esserci più di 2 frame validi\n",
        "        first_valid = valid_frames[0]\n",
        "        last_valid = valid_frames[-1]\n",
        "\n",
        "        # Controlla se il blocco è statico e se ha abbastanza frame -1, -1 prima e dopo\n",
        "        if is_static_block(values, first_valid, last_valid, static_threshold) and has_null_neighbors(values, first_valid, last_valid, min_neighbors):\n",
        "            # Setta tutti i frame della finestra a -1, -1\n",
        "            for j in range(start, end):\n",
        "                cleaned_predictions[frames[j]] = {\"x\": -1, \"y\": -1}\n",
        "            #print(f\"Blocco da {frames[start]} a {frames[end-1]} impostato a -1, -1.\")\n",
        "\n",
        "\n",
        "\n",
        "# Salva il file JSON depurato\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(cleaned_predictions, f, indent=4)\n",
        "\n",
        "print(f\"Predizioni depurate salvate in: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voHmrcEuO3Lx"
      },
      "source": [
        "## Riduzione falsi negativi\n",
        "\n",
        "### Metodo di Interpolazione:\n",
        "\n",
        "Per ridurre le situazioni in cui il modello riscontra difficoltà nella tracking della palla si utilizza il metodo dell'**interpolazione lineare**, che calcola le coordinate intermedie tra:\n",
        "Ultimo frame prima del buco.\n",
        "Primo frame dopo il buco.\n",
        "La traiettoria viene ricostruita dividendo lo spostamento totale tra le due posizioni in intervalli uguali per ogni frame mancante.\n",
        "Limite di 20 Frame:\n",
        "\n",
        "Limitiamo l'interpolazione a 20 frame consecutivi per garantire che le predizioni siano ancora realistiche:\n",
        "Per buchi più lunghi, è probabile che il pallone abbia cambiato direzione o sia stato influenzato da eventi esterni, rendendo l'interpolazione meno affidabile."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVDiljokN7L4",
        "outputId": "265b0ad1-2f23-4f4a-8143-1c95aca44ef1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Percorso del file JSON di input e output\n",
        "input_file = '/content/drive/MyDrive/model/yolo_output/video6_SenzaOutlier.json'\n",
        "output_file = '/content/drive/MyDrive/model/yolo_output/video6_Interpolato.json'\n",
        "\n",
        "# Carica il file JSON di input\n",
        "with open(input_file, 'r') as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "# Converte le predizioni in una lista per iterazione\n",
        "frames = list(predictions.keys())\n",
        "values = list(predictions.values())\n",
        "\n",
        "# Numero massimo di buchi da interpolare\n",
        "max_gap = 20\n",
        "\n",
        "# Funzione per interpolare\n",
        "def interpolate_frames(start_coords, end_coords, gap_length):\n",
        "    \"\"\"Interpolazione lineare tra due estremi.\"\"\"\n",
        "    interpolated = []\n",
        "    x_step = (end_coords[\"x\"] - start_coords[\"x\"]) / (gap_length + 1)\n",
        "    y_step = (end_coords[\"y\"] - start_coords[\"y\"]) / (gap_length + 1)\n",
        "    for i in range(1, gap_length + 1):\n",
        "        interpolated.append({\n",
        "            \"x\": start_coords[\"x\"] + i * x_step,\n",
        "            \"y\": start_coords[\"y\"] + i * y_step\n",
        "        })\n",
        "    return interpolated\n",
        "\n",
        "# Itera sui frame per identificare e riempire i buchi\n",
        "cleaned_predictions = predictions.copy()\n",
        "i = 0\n",
        "\n",
        "while i < len(values):\n",
        "    # Trova l'inizio del buco\n",
        "    if values[i][\"x\"] != -1 and values[i][\"y\"] != -1:\n",
        "        start_index = i\n",
        "        # Cerca l'inizio del buco\n",
        "        i += 1\n",
        "        while i < len(values) and values[i][\"x\"] == -1 and values[i][\"y\"] == -1:\n",
        "            i += 1\n",
        "        end_index = i\n",
        "\n",
        "        # Se il buco è valido e non troppo grande\n",
        "        gap_length = end_index - start_index - 1\n",
        "        if gap_length > 0 and gap_length <= max_gap and end_index < len(values):\n",
        "            # Ottieni le coordinate degli estremi\n",
        "            start_coords = values[start_index]\n",
        "            end_coords = values[end_index]\n",
        "\n",
        "            # Interpola i frame mancanti\n",
        "            interpolated = interpolate_frames(start_coords, end_coords, gap_length)\n",
        "\n",
        "            # Aggiorna i frame mancanti con le coordinate interpolate\n",
        "            for j in range(gap_length):\n",
        "                frame_index = start_index + j + 1\n",
        "                cleaned_predictions[frames[frame_index]] = interpolated[j]\n",
        "                print(f\"Frame {frames[frame_index]} interpolato: {interpolated[j]}\")\n",
        "    else:\n",
        "        i += 1\n",
        "\n",
        "# Salva il file JSON con i frame interpolati\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(cleaned_predictions, f, indent=4)\n",
        "\n",
        "print(f\"Predizioni interpolate salvate in: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGwIg6A0z5lQ"
      },
      "source": [
        "### Edge Handling\n",
        "Infine la tecnica di edge handling viene utilizzata per gestire predizioni che terminano in una posizione vicina al bordo dell'immagine, ma non direttamente sul bordo. Questo comportamento spesso indica che il pallone sta uscendo dal campo visivo, ma la predizione si interrompe prematuramente.\n",
        "\n",
        "* In un contesto realistico, il pallone si muove frequentemente verso i bordi del frame, ad esempio durante tiri, passaggi lunghi o situazioni di gioco veloci.\n",
        "* Utilizzando la velocità e la direzione calcolate dai frame precedenti, estendiamo la predizione in modo graduale fino a quando il pallone raggiunge il bordo, migliorando così la continuità del tracciamento.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iff7QF4k0Quw",
        "outputId": "c083d7fc-b7e1-4b27-b495-01ad6d739c51"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Percorso del file JSON di input e output\n",
        "input_file = '/content/drive/MyDrive/model/yolo_output/video6_Interpolato.json'\n",
        "output_file = '/content/drive/MyDrive/model/yolo_output/video6_252320.json'\n",
        "\n",
        "# Carica il file JSON di input\n",
        "with open(input_file, 'r') as f:\n",
        "    predictions = json.load(f)\n",
        "\n",
        "# Dimensioni dell'immagine\n",
        "img_width = 1920\n",
        "img_height = 1080\n",
        "\n",
        "# Converte le predizioni in una lista per iterazione\n",
        "frames = list(predictions.keys())\n",
        "values = list(predictions.values())\n",
        "\n",
        "# Funzione per verificare se una posizione è fuori dai bordi\n",
        "def is_out_of_bounds(x, y, img_width, img_height):\n",
        "    return x < 0 or x > img_width or y < 0 or y > img_height\n",
        "\n",
        "# Itera sui frame per estendere i blocchi validi\n",
        "cleaned_predictions = predictions.copy()\n",
        "i = 0\n",
        "\n",
        "while i < len(values):\n",
        "    # Trova il blocco di frame validi\n",
        "    if values[i][\"x\"] != -1 and values[i][\"y\"] != -1:\n",
        "        start_index = i\n",
        "        while i < len(values) and values[i][\"x\"] != -1 and values[i][\"y\"] != -1:\n",
        "            i += 1\n",
        "        end_index = i - 1\n",
        "\n",
        "        # Verifica se il blocco termina senza essere ai bordi\n",
        "        last_coords = values[end_index]\n",
        "        if not is_out_of_bounds(last_coords[\"x\"], last_coords[\"y\"], img_width, img_height):\n",
        "            # Calcola lo scarto usando gli ultimi due frame validi\n",
        "            if end_index > start_index:  # Assicuriamoci che ci siano almeno due frame validi\n",
        "                second_last_coords = values[end_index - 1]\n",
        "                delta_x = last_coords[\"x\"] - second_last_coords[\"x\"]\n",
        "                delta_y = last_coords[\"y\"] - second_last_coords[\"y\"]\n",
        "\n",
        "                # Estendi i frame successivi finché non si raggiunge un bordo\n",
        "                current_x = last_coords[\"x\"]\n",
        "                current_y = last_coords[\"y\"]\n",
        "                frame_index = end_index + 1\n",
        "\n",
        "                while frame_index < len(values):\n",
        "                    current_x += delta_x\n",
        "                    current_y += delta_y\n",
        "\n",
        "                    # Se la palla esce dai bordi, interrompi\n",
        "                    if is_out_of_bounds(current_x, current_y, img_width, img_height):\n",
        "                        break\n",
        "\n",
        "                    # Aggiorna il frame con le nuove coordinate\n",
        "                    cleaned_predictions[frames[frame_index]] = {\"x\": current_x, \"y\": current_y}\n",
        "                    print(f\"Frame {frames[frame_index]} esteso: ({current_x}, {current_y})\")\n",
        "\n",
        "                    frame_index += 1\n",
        "    else:\n",
        "        i += 1\n",
        "\n",
        "# Salva il file JSON con i frame estesi\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(cleaned_predictions, f, indent=4)\n",
        "\n",
        "print(f\"Predizioni estese salvate in: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6q_Q5Kr2etk"
      },
      "source": [
        "# Valutiamo con classe Tracking Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9YCf7dNjw3"
      },
      "source": [
        "Dopo aver applicato le tecniche di **post-processing**, rivalutiamo le metriche del modello per verificare i miglioramenti ottenuti. Ci aspettiamo un aumento significativo delle prestazioni, con una riduzione dei falsi positivi e una gestione più accurata dei falsi negativi. In particolare, l'**interpolazione lineare** e l'**edge handling** hanno reso i movimenti del pallone più naturali e fluidi, migliorando la coerenza del tracciamento. Questi interventi hanno contribuito a un notevole incremento nell'accuratezza complessiva delle predizioni, rendendo il modello più robusto e affidabile."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weibsoFj2l4h"
      },
      "source": [
        "## MSE per Video 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRhvhzZvQ2dC",
        "outputId": "c70beff9-f627-4ff8-ed8c-593874168731"
      },
      "outputs": [],
      "source": [
        "# Percorsi ai tuoi file\n",
        "gt_ann_file = '/content/drive/MyDrive/dataset/dataset_soccer/test/ID-5.xml'  # Ground truth file\n",
        "pred_file = '/content/drive/MyDrive/model/yolo_output/video5_252320.json'  # Predizioni in formato JSON\n",
        "\n",
        "# Creazione dell'oggetto evaluator\n",
        "evaluator = TrackingEvaluator(gt_ann_file, pred_file)\n",
        "\n",
        "# Caricamento dei dati\n",
        "evaluator.load_data()\n",
        "\n",
        "# Calcolare gli indici dei frame\n",
        "evaluator.compute_frame_indices()\n",
        "\n",
        "# Valutazione delle metriche\n",
        "evaluator.evaluate_metrics()\n",
        "\n",
        "# Calcolare MSE\n",
        "mse1 = evaluator.compute_mse()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD0gLjRE2pCP"
      },
      "source": [
        "##MSE per video 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UvHtRDvzycz",
        "outputId": "66c728fe-03fc-4786-f8eb-1368a8ab4366"
      },
      "outputs": [],
      "source": [
        "# Percorsi ai tuoi file\n",
        "gt_ann_file = '/content/drive/MyDrive/dataset/dataset_soccer/test/ID-6.xml'  # Ground truth file\n",
        "pred_file = '/content/drive/MyDrive/model/yolo_output/video6_252320.json'  # Predizioni in formato JSON\n",
        "\n",
        "# Creazione dell'oggetto evaluator\n",
        "evaluator = TrackingEvaluator(gt_ann_file, pred_file)\n",
        "\n",
        "# Caricamento dei dati\n",
        "evaluator.load_data()\n",
        "\n",
        "# Calcolare gli indici dei frame\n",
        "evaluator.compute_frame_indices()\n",
        "\n",
        "# Valutazione delle metriche\n",
        "evaluator.evaluate_metrics()\n",
        "\n",
        "# Calcolare MSE\n",
        "mse2 = evaluator.compute_mse()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGkA5bRd2sjX",
        "outputId": "cd46e227-50db-467b-b721-8a7c5c6a4e50"
      },
      "outputs": [],
      "source": [
        "media=(mse1+mse2)/2\n",
        "print(\"Risultato ottenuto:\",media)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWgtUQ5HOA4B"
      },
      "source": [
        "\n",
        "# **Metriche Obiettivo Finali**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "QXaRo5MzOm2Z",
        "outputId": "95c9c87e-c4c0-4349-edb4-b614f518edec"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Crea una tabella markdown per mostrare le metriche\n",
        "table_md = \"\"\"\n",
        "# **Metriche Obiettivo Finali**\n",
        "\n",
        "| **Metrica**    | **VIDEO 5** | **VIDEO 6** | **MEDIA**     |\n",
        "|----------------|-------------|-------------|---------------|\n",
        "| **MSE**        | 0.0384      | 0.00225     | 0.020332      |\n",
        "\"\"\"\n",
        "\n",
        "# Mostra la tabella in Colab\n",
        "display(Markdown(table_md))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A0NPND_U9JE"
      },
      "source": [
        "#Generazione dei video con traiettoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce7cwJWCVArn",
        "outputId": "314fb93c-4768-4a0d-85d5-40c808f92c15"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "\n",
        "def draw_bounding_boxes_with_trajectory(image_path, prediction, trajectory, max_frames, max_distance=100, color=(0, 0, 255)):\n",
        "    \"\"\"\n",
        "    Disegna i bounding box e la traiettoria su un'immagine usando le predizioni JSON,\n",
        "    mantenendo solo una traccia limitata nel tempo e smorzando variazioni eccessive.\n",
        "\n",
        "    :param image_path: Percorso dell'immagine.\n",
        "    :param prediction: Predizione (dizionario con 'x' e 'y').\n",
        "    :param trajectory: Lista delle coordinate precedenti per la traiettoria.\n",
        "    :param max_frames: Numero massimo di frame da mantenere nella traiettoria.\n",
        "    :param max_distance: Distanza massima consentita tra due punti consecutivi per la traiettoria.\n",
        "    :param color: Colore del bounding box e della traiettoria.\n",
        "    :return: Immagine con bounding box e traiettoria sovrapposti.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Immagine non trovata: {image_path}\")\n",
        "        return None\n",
        "\n",
        "    height, width, _ = image.shape\n",
        "    current_position = None\n",
        "\n",
        "    if prediction[\"x\"] != -1 and prediction[\"y\"] != -1:\n",
        "        x = prediction[\"x\"]\n",
        "        y = prediction[\"y\"]\n",
        "        box_size = 50  # Dimensione del bounding box in pixel\n",
        "        x1 = int(x - box_size / 2)\n",
        "        y1 = int(y - box_size / 2)\n",
        "        x2 = int(x + box_size / 2)\n",
        "        y2 = int(y + box_size / 2)\n",
        "\n",
        "        # Salva la posizione corrente per la traiettoria\n",
        "        current_position = (x, y)\n",
        "\n",
        "        # Disegna il bounding box\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(image, \"Ball\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "\n",
        "    # Controllo variazione eccessiva\n",
        "    if trajectory and current_position:\n",
        "        last_position = trajectory[-1]\n",
        "        if last_position is not None:\n",
        "            distance = math.sqrt((current_position[0] - last_position[0]) ** 2 +\n",
        "                                 (current_position[1] - last_position[1]) ** 2)\n",
        "            if distance > max_distance:\n",
        "                print(f\"Variazione eccessiva ignorata: {distance:.2f} pixel\")\n",
        "                current_position = None\n",
        "\n",
        "    # Disegna la traiettoria\n",
        "    if trajectory and len(trajectory) > 1:\n",
        "        for i in range(1, len(trajectory)):\n",
        "            if trajectory[i - 1] is not None and trajectory[i] is not None:\n",
        "                pt1 = tuple(map(int, trajectory[i - 1]))\n",
        "                pt2 = tuple(map(int, trajectory[i]))\n",
        "                cv2.line(image, pt1, pt2, color, 2)\n",
        "\n",
        "\n",
        "    # Aggiungi la posizione corrente alla traiettoria\n",
        "    if current_position:\n",
        "        trajectory.append(current_position)\n",
        "    else:\n",
        "        trajectory.append(None)  # Interrompe la traiettoria se la palla non è visibile\n",
        "\n",
        "    if len(trajectory) > max_frames:\n",
        "        trajectory.pop(0)  # Rimuovi i punti più vecchi\n",
        "\n",
        "    return image\n",
        "\n",
        "def create_video_with_bboxes_and_trajectory_json(image_dir, json_file, output_video_path, fps=25, max_trajectory_seconds=0.5):\n",
        "    \"\"\"\n",
        "    Crea un video con bounding box e traiettoria sovrapposti usando predizioni da file JSON.\n",
        "\n",
        "    :param image_dir: Directory contenente le immagini.\n",
        "    :param json_file: File JSON contenente le predizioni.\n",
        "    :param output_video_path: Percorso per salvare il video generato.\n",
        "    :param fps: Frame per secondo del video.\n",
        "    :param max_trajectory_seconds: Numero massimo di secondi da mantenere nella traiettoria.\n",
        "    \"\"\"\n",
        "    # Carica le predizioni\n",
        "    with open(json_file, \"r\") as f:\n",
        "        predictions = json.load(f)\n",
        "\n",
        "    # Ottieni la lista delle immagini\n",
        "    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(\".jpg\")])\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"Nessuna immagine trovata nella directory: {image_dir}\")\n",
        "        return\n",
        "\n",
        "    # Leggi la prima immagine per ottenere dimensioni\n",
        "    first_image_path = os.path.join(image_dir, image_files[0])\n",
        "    first_image = cv2.imread(first_image_path)\n",
        "    height, width, _ = first_image.shape\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec per MP4\n",
        "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    trajectory = []  # Lista per salvare la traiettoria\n",
        "    max_frames = int(max_trajectory_seconds * fps)  # Numero massimo di frame nella traiettoria\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(image_dir, image_file)\n",
        "        frame_number = image_file.split(\"_frame\")[1].split(\".\")[0]  # Es. \"000000\"\n",
        "        json_key = f\"{frame_number}.jpg\"  # Es. \"000000.jpg\"\n",
        "\n",
        "        # Ottieni la predizione dal file JSON\n",
        "        prediction = predictions.get(json_key, {\"x\": -1, \"y\": -1})\n",
        "\n",
        "        # Disegna bounding box e traiettoria\n",
        "        annotated_image = draw_bounding_boxes_with_trajectory(image_path, prediction, trajectory, max_frames)\n",
        "        if annotated_image is not None:\n",
        "            video_writer.write(annotated_image)\n",
        "\n",
        "    video_writer.release()\n",
        "    print(f\"Video generato con successo: {output_video_path}\")\n",
        "\n",
        "# Percorsi per il video 6\n",
        "image_dir = \"/content/drive/MyDrive/dataset/test/video5\"  # Directory immagini di test\n",
        "json_file = \"/content/drive/MyDrive/model/yolo_output/video5_252320.json\"  # Predizioni per video 6\n",
        "output_video = \"/content/drive/MyDrive/model/yolo_output/videoAnnotato5.mp4\"  # Video di output per video 6\n",
        "\n",
        "# Crea il video\n",
        "create_video_with_bboxes_and_trajectory_json(image_dir, json_file, output_video, fps=25, max_trajectory_seconds=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaJVOZ6pMECg",
        "outputId": "6763ebe1-7f73-4732-9457-ca6143958f1e"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "\n",
        "def draw_bounding_boxes_with_trajectory(image_path, prediction, trajectory, max_frames, max_distance=100, color=(0, 0, 255)):\n",
        "    \"\"\"\n",
        "    Disegna i bounding box e la traiettoria su un'immagine usando le predizioni JSON,\n",
        "    mantenendo solo una traccia limitata nel tempo e smorzando variazioni eccessive.\n",
        "\n",
        "    :param image_path: Percorso dell'immagine.\n",
        "    :param prediction: Predizione (dizionario con 'x' e 'y').\n",
        "    :param trajectory: Lista delle coordinate precedenti per la traiettoria.\n",
        "    :param max_frames: Numero massimo di frame da mantenere nella traiettoria.\n",
        "    :param max_distance: Distanza massima consentita tra due punti consecutivi per la traiettoria.\n",
        "    :param color: Colore del bounding box e della traiettoria.\n",
        "    :return: Immagine con bounding box e traiettoria sovrapposti.\n",
        "    \"\"\"\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Immagine non trovata: {image_path}\")\n",
        "        return None\n",
        "\n",
        "    height, width, _ = image.shape\n",
        "    current_position = None\n",
        "\n",
        "    if prediction[\"x\"] != -1 and prediction[\"y\"] != -1:\n",
        "        x = prediction[\"x\"]\n",
        "        y = prediction[\"y\"]\n",
        "        box_size = 50  # Dimensione del bounding box in pixel\n",
        "        x1 = int(x - box_size / 2)\n",
        "        y1 = int(y - box_size / 2)\n",
        "        x2 = int(x + box_size / 2)\n",
        "        y2 = int(y + box_size / 2)\n",
        "\n",
        "        # Salva la posizione corrente per la traiettoria\n",
        "        current_position = (x, y)\n",
        "\n",
        "        # Disegna il bounding box\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        cv2.putText(image, \"Ball\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "\n",
        "    # Controllo variazione eccessiva\n",
        "    if trajectory and current_position:\n",
        "        last_position = trajectory[-1]\n",
        "        if last_position is not None:\n",
        "            distance = math.sqrt((current_position[0] - last_position[0]) ** 2 +\n",
        "                                 (current_position[1] - last_position[1]) ** 2)\n",
        "            if distance > max_distance:\n",
        "                print(f\"Variazione eccessiva ignorata: {distance:.2f} pixel\")\n",
        "                current_position = None\n",
        "\n",
        "    # Disegna la traiettoria\n",
        "    if trajectory and len(trajectory) > 1:\n",
        "        for i in range(1, len(trajectory)):\n",
        "            if trajectory[i - 1] is not None and trajectory[i] is not None:\n",
        "                pt1 = tuple(map(int, trajectory[i - 1]))\n",
        "                pt2 = tuple(map(int, trajectory[i]))\n",
        "                cv2.line(image, pt1, pt2, color, 2)\n",
        "\n",
        "\n",
        "    # Aggiungi la posizione corrente alla traiettoria\n",
        "    if current_position:\n",
        "        trajectory.append(current_position)\n",
        "    else:\n",
        "        trajectory.append(None)  # Interrompe la traiettoria se la palla non è visibile\n",
        "\n",
        "    if len(trajectory) > max_frames:\n",
        "        trajectory.pop(0)  # Rimuovi i punti più vecchi\n",
        "\n",
        "    return image\n",
        "\n",
        "def create_video_with_bboxes_and_trajectory_json(image_dir, json_file, output_video_path, fps=25, max_trajectory_seconds=0.5):\n",
        "    \"\"\"\n",
        "    Crea un video con bounding box e traiettoria sovrapposti usando predizioni da file JSON.\n",
        "\n",
        "    :param image_dir: Directory contenente le immagini.\n",
        "    :param json_file: File JSON contenente le predizioni.\n",
        "    :param output_video_path: Percorso per salvare il video generato.\n",
        "    :param fps: Frame per secondo del video.\n",
        "    :param max_trajectory_seconds: Numero massimo di secondi da mantenere nella traiettoria.\n",
        "    \"\"\"\n",
        "    # Carica le predizioni\n",
        "    with open(json_file, \"r\") as f:\n",
        "        predictions = json.load(f)\n",
        "\n",
        "    # Ottieni la lista delle immagini\n",
        "    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(\".jpg\")])\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"Nessuna immagine trovata nella directory: {image_dir}\")\n",
        "        return\n",
        "\n",
        "    # Leggi la prima immagine per ottenere dimensioni\n",
        "    first_image_path = os.path.join(image_dir, image_files[0])\n",
        "    first_image = cv2.imread(first_image_path)\n",
        "    height, width, _ = first_image.shape\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec per MP4\n",
        "    video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    trajectory = []  # Lista per salvare la traiettoria\n",
        "    max_frames = int(max_trajectory_seconds * fps)  # Numero massimo di frame nella traiettoria\n",
        "\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(image_dir, image_file)\n",
        "        frame_number = image_file.split(\"_frame\")[1].split(\".\")[0]  # Es. \"000000\"\n",
        "        json_key = f\"{frame_number}.jpg\"  # Es. \"000000.jpg\"\n",
        "\n",
        "        # Ottieni la predizione dal file JSON\n",
        "        prediction = predictions.get(json_key, {\"x\": -1, \"y\": -1})\n",
        "\n",
        "        # Disegna bounding box e traiettoria\n",
        "        annotated_image = draw_bounding_boxes_with_trajectory(image_path, prediction, trajectory, max_frames)\n",
        "        if annotated_image is not None:\n",
        "            video_writer.write(annotated_image)\n",
        "\n",
        "    video_writer.release()\n",
        "    print(f\"Video generato con successo: {output_video_path}\")\n",
        "\n",
        "# Percorsi per il video 6\n",
        "image_dir = \"/content/drive/MyDrive/dataset/test/video6\"  # Directory immagini di test\n",
        "json_file = \"/content/drive/MyDrive/model/yolo_output/video6_252320.json\"  # Predizioni per video 6\n",
        "output_video = \"/content/drive/MyDrive/model/yolo_output/videoAnnotato6.mp4\"  # Video di output per video 6\n",
        "\n",
        "# Crea il video\n",
        "create_video_with_bboxes_and_trajectory_json(image_dir, json_file, output_video, fps=25, max_trajectory_seconds=0.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBQYAfo_Pi68"
      },
      "source": [
        "# Conclusioni\n",
        "Prospettive future e possibili miglioramenti\n",
        "\n",
        "* Raccogliere più dati con situazioni diverse (occlusioni, angolazioni, condizioni di illuminazione variabili).\n",
        "* Aumentare la varietà di esempi per migliorare la generalizzazione del modello.\n",
        "* Applicare metodi di interpolazione più sofisticati per migliorare la gestione dei falsi negativi.\n",
        "* Sperimentazione con Modelli Più Complessi(es. YOLO11X)\n",
        "* Integrazione con Sistemi Avanzati"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
